{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOs298BH8he+bIA+1bR4KW7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["### Change runtime to use GPU:\n","**Runtime** -> Change runtime type -> Hardware Accelerator -> **GPU** -> GPU Type -> **T4**"],"metadata":{"id":"d-5Cwodd3pu6"}},{"cell_type":"markdown","source":["###**Check Nvidia Cuda Compiler version (nvcc)**✅"],"metadata":{"id":"yBkQovd0WfuU"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ewbc6E_nV51O","executionInfo":{"status":"ok","timestamp":1690579766437,"user_tz":240,"elapsed":185,"user":{"displayName":"Akshit Mishra","userId":"07662821470294555919"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"382b70b6-2bfd-4083-886a-82b7c74fd438"},"outputs":[{"output_type":"stream","name":"stdout","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2022 NVIDIA Corporation\n","Built on Wed_Sep_21_10:33:58_PDT_2022\n","Cuda compilation tools, release 11.8, V11.8.89\n","Build cuda_11.8.r11.8/compiler.31833905_0\n"]}],"source":["!nvcc --version"]},{"cell_type":"markdown","source":["###**Install a small extension to run nvcc from the Notebook cells** 🔧"],"metadata":{"id":"Df0mU6jTXym5"}},{"cell_type":"code","source":["!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"],"metadata":{"id":"Zk8IjEV0Yk2i","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690579792206,"user_tz":240,"elapsed":7631,"user":{"displayName":"Akshit Mishra","userId":"07662821470294555919"}},"outputId":"9c1ad369-c942-4b8d-bd93-49e787928b85"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n","  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-45u9cb1k\n","  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-45u9cb1k\n","  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit aac710a35f52bb78ab34d2e52517237941399eff\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: NVCCPlugin\n","  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4288 sha256=6495c3728a9a0de1c0175c651b2f608a65f9558528f0f0bb0d18564dc74b9c29\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-00g8zqdt/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n","Successfully built NVCCPlugin\n","Installing collected packages: NVCCPlugin\n","Successfully installed NVCCPlugin-0.0.2\n"]}]},{"cell_type":"markdown","source":["###**Load the extension using the code given below** 🖥"],"metadata":{"id":"SgDAi7MjYpr-"}},{"cell_type":"code","source":["%load_ext nvcc_plugin"],"metadata":{"id":"AJLCMv4pY5YM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690579803780,"user_tz":240,"elapsed":169,"user":{"displayName":"Akshit Mishra","userId":"07662821470294555919"}},"outputId":"a5628060-6bd7-4b69-9033-d0c8f4132502"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["created output directory at /content/src\n","Out bin /content/result.out\n"]}]},{"cell_type":"markdown","source":["###**Run code** 🤖"],"metadata":{"id":"fr__eIyvY-_A"}},{"cell_type":"code","source":["%%cu\n","#include <iostream>\n","    int\n","    main()\n","{\n","    std::cout << \"Welcome To Robotics Playground\\n\";\n","    return 0;\n","}"],"metadata":{"id":"qFzprBXnZIq2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690579816954,"user_tz":240,"elapsed":3440,"user":{"displayName":"Akshit Mishra","userId":"07662821470294555919"}},"outputId":"5aa93fcb-d14e-4fd9-9e2b-72483fad4295"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Welcome To Robotics Playground\n","\n"]}]},{"cell_type":"markdown","source":["###**Learn about your GPU** 🔍"],"metadata":{"id":"PDtihow3ZTWN"}},{"cell_type":"code","source":["%%cu\n","\n","#include <cstdio>\n","#include <iostream>\n","\n","using namespace std;\n","\n","int main() {\n","\n","  int nDevices;\n","  cudaGetDeviceCount(&nDevices);\n","\n","  printf(\"Number of devices: %d\\n\", nDevices);\n","\n","  for (int i = 0; i < nDevices; i++) {\n","    cudaDeviceProp prop;\n","    cudaGetDeviceProperties(&prop, i);\n","    printf(\"Device Number: %d\\n\", i);\n","    printf(\"  Device name: %s\\n\", prop.name);\n","    printf(\"  Memory Clock Rate (MHz): %d\\n\",\n","           prop.memoryClockRate/1024);\n","    printf(\"  Memory Bus Width (bits): %d\\n\",\n","           prop.memoryBusWidth);\n","    printf(\"  Peak Memory Bandwidth (GB/s): %.1f\\n\",\n","           2.0*prop.memoryClockRate*(prop.memoryBusWidth/8)/1.0e6);\n","    printf(\"  Total global memory (Gbytes) %.1f\\n\",(float)(prop.totalGlobalMem)/1024.0/1024.0/1024.0);\n","    printf(\"  Shared memory per block (Kbytes) %.1f\\n\",(float)(prop.sharedMemPerBlock)/1024.0);\n","    printf(\"  minor-major: %d-%d\\n\", prop.minor, prop.major);\n","    printf(\"  Warp-size: %d\\n\", prop.warpSize);\n","    printf(\"  Concurrent kernels: %s\\n\", prop.concurrentKernels ? \"yes\" : \"no\");\n","    printf(\"  Concurrent computation/communication: %s\\n\\n\",prop.deviceOverlap ? \"yes\" : \"no\");\n","  }\n","}"],"metadata":{"id":"PrAcJ_iXZc7y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690579842753,"user_tz":240,"elapsed":2138,"user":{"displayName":"Akshit Mishra","userId":"07662821470294555919"}},"outputId":"6dd079bf-172e-4491-8903-b7d45037aeb0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of devices: 1\n","Device Number: 0\n","  Device name: Tesla T4\n","  Memory Clock Rate (MHz): 4883\n","  Memory Bus Width (bits): 256\n","  Peak Memory Bandwidth (GB/s): 320.1\n","  Total global memory (Gbytes) 14.7\n","  Shared memory per block (Kbytes) 48.0\n","  minor-major: 5-7\n","  Warp-size: 32\n","  Concurrent kernels: yes\n","  Concurrent computation/communication: yes\n","\n","\n"]}]}]}